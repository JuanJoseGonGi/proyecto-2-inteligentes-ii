{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import gymnasium as gym\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountain_env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DQN(tf.keras.models.Model):\n",
    "    def __init__(self, hidden_layers, output_layer):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"hidden_layers\": self.hidden_layers,\n",
    "            \"output_layer\": self.output_layer,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        hidden_layers = []\n",
    "        for layer in config[\"hidden_layers\"]:\n",
    "            hidden_layers.append(tf.keras.layers.Dense(**layer[\"config\"]))\n",
    "        output_layer = tf.keras.layers.Dense(**config[\"output_layer\"][\"config\"])\n",
    "        return cls(hidden_layers, output_layer)\n",
    "\n",
    "\n",
    "def reshape_reward(reward, next_state, current_state, speed_weight):\n",
    "    return reward + speed_weight * (np.abs(next_state[1]) - np.abs(current_state[1]))\n",
    "\n",
    "\n",
    "def evaluate_mountain_model(model, speed_weight, evaluation_episodes=100):\n",
    "    rewards, reshaped_rewards = [], []\n",
    "    for _ in range(evaluation_episodes):\n",
    "        state, _ = mountain_env.reset()\n",
    "        done, truncated = False, False\n",
    "        accumulated_reward, accumulated_reshaped_reward = 0, 0\n",
    "        while not done and not truncated:\n",
    "            state_in = tf.expand_dims(state, axis=0)\n",
    "            action = tf.argmax(model(state_in)[0]).numpy()\n",
    "            next_state, reward, done, truncated, _ = mountain_env.step(action)\n",
    "            accumulated_reward += reward\n",
    "            accumulated_reshaped_reward += reshape_reward(\n",
    "                reward, next_state, state, speed_weight\n",
    "            )\n",
    "            state = next_state\n",
    "        rewards.append(accumulated_reward)\n",
    "        reshaped_rewards.append(accumulated_reshaped_reward)\n",
    "    return rewards, reshaped_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountain_models_path = \"mountain/models\"\n",
    "mountain_metrics_path = \"mountain/metrics\"\n",
    "mountain_hyperparams_path = \"mountain/hyperparams\"\n",
    "\n",
    "\n",
    "def load_model_data(model_name_with_extension):\n",
    "    model_name = model_name_with_extension.split(\".\")[0]\n",
    "    metrics = np.load(\n",
    "        os.path.join(mountain_metrics_path, f\"{model_name}_metrics.npy\"),\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    hyperparams = np.load(\n",
    "        os.path.join(mountain_hyperparams_path, f\"{model_name}_hyperparams.npy\"),\n",
    "        allow_pickle=True,\n",
    "    ).item()\n",
    "    speed_weight = hyperparams.get(\"speed_weight\", 10)\n",
    "    model = load_model(\n",
    "        os.path.join(mountain_models_path, f\"{model_name_with_extension}\")\n",
    "    )\n",
    "\n",
    "    return model_name, metrics, hyperparams, speed_weight, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15_13-41-53_dqn_mountaincar\n",
      "[-138.0, -145.0, -147.0, -140.0, -110.0, -138.0, -140.0, -140.0, -144.0, -111.0]\n",
      "2024-06-15_16-46-16_dqn_mountaincar\n",
      "[-111.0, -111.0, -142.0, -114.0, -124.0, -117.0, -121.0, -142.0, -142.0, -116.0]\n",
      "2024-06-15_12-43-26_dqn_mountaincar\n",
      "[-147.0, -147.0, -200.0, -168.0, -143.0, -143.0, -169.0, -169.0, -146.0, -147.0]\n",
      "2024-06-15_13-02-52_dqn_mountaincar\n",
      "[-141.0, -144.0, -149.0, -144.0, -140.0, -112.0, -139.0, -140.0, -137.0, -141.0]\n",
      "2024-06-15_12-35-51_dqn_mountaincar\n",
      "[-141.0, -85.0, -145.0, -152.0, -90.0, -113.0, -113.0, -112.0, -141.0, -84.0]\n",
      "2024-06-15_12-43-21_dqn_mountaincar\n",
      "[-113.0, -148.0, -83.0, -109.0, -109.0, -153.0, -147.0, -148.0, -112.0, -109.0]\n",
      "2024-06-15_10-54-10_dqn_mountaincar\n",
      "[-145.0, -144.0, -140.0, -108.0, -109.0, -109.0, -112.0, -112.0, -141.0, -109.0]\n",
      "2024-06-15_11-57-24_dqn_mountaincar\n",
      "[-119.0, -160.0, -118.0, -118.0, -151.0, -117.0, -153.0, -160.0, -153.0, -172.0]\n",
      "2024-06-15_13-39-22_dqn_mountaincar\n",
      "[-149.0, -154.0, -154.0, -148.0, -153.0, -147.0, -196.0, -197.0, -152.0, -153.0]\n",
      "2024-06-15_12-16-56_dqn_mountaincar\n",
      "[-139.0, -142.0, -144.0, -174.0, -143.0, -153.0, -144.0, -141.0, -109.0, -143.0]\n",
      "2024-06-15_13-48-51_dqn_mountaincar\n",
      "[-112.0, -84.0, -95.0, -97.0, -112.0, -111.0, -94.0, -110.0, -163.0, -111.0]\n",
      "2024-06-15_13-20-27_dqn_mountaincar\n",
      "[-141.0, -155.0, -140.0, -146.0, -140.0, -85.0, -155.0, -141.0, -153.0, -87.0]\n",
      "2024-06-15_13-00-05_dqn_mountaincar\n",
      "[-112.0, -111.0, -85.0, -91.0, -111.0, -151.0, -87.0, -95.0, -111.0, -87.0]\n",
      "2024-06-15_13-36-42_dqn_mountaincar\n",
      "[-92.0, -141.0, -111.0, -146.0, -90.0, -146.0, -147.0, -114.0, -146.0, -110.0]\n",
      "2024-06-15_13-56-21_dqn_mountaincar\n",
      "[-86.0, -103.0, -96.0, -91.0, -101.0, -169.0, -88.0, -110.0, -86.0, -108.0]\n",
      "2024-06-15_13-45-47_dqn_mountaincar\n",
      "[-181.0, -150.0, -149.0, -90.0, -150.0, -147.0, -150.0, -152.0, -181.0, -152.0]\n",
      "2024-06-15_12-31-16_dqn_mountaincar\n",
      "[-108.0, -145.0, -147.0, -108.0, -108.0, -114.0, -111.0, -87.0, -110.0, -147.0]\n",
      "2024-06-15_13-45-28_dqn_mountaincar\n",
      "[-200.0, -200.0, -200.0, -108.0, -200.0, -112.0, -112.0, -113.0, -200.0, -200.0]\n",
      "2024-06-15_08-13-32_dqn_mountaincar\n",
      "[-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]\n",
      "2024-06-15_12-23-27_dqn_mountaincar\n",
      "[-139.0, -141.0, -140.0, -142.0, -150.0, -154.0, -87.0, -149.0, -110.0, -110.0]\n",
      "2024-06-15_11-21-25_dqn_mountaincar\n",
      "[-108.0, -138.0, -152.0, -112.0, -143.0, -144.0, -150.0, -112.0, -161.0, -142.0]\n",
      "2024-06-15_11-01-53_dqn_mountaincar\n",
      "[-111.0, -145.0, -110.0, -145.0, -151.0, -141.0, -107.0, -108.0, -108.0, -145.0]\n"
     ]
    }
   ],
   "source": [
    "mountain_models_paths = os.listdir(mountain_models_path)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for model_name_with_extension in mountain_models_paths:\n",
    "    model_name, metrics, hyperparams, speed_weight, model = load_model_data(\n",
    "        model_name_with_extension\n",
    "    )\n",
    "    print(model_name)\n",
    "    evaluate_rewards, evaluate_reshaped_rewards = evaluate_mountain_model(\n",
    "        model, speed_weight, 10\n",
    "    )\n",
    "    units_per_layer = [layer.units for layer in model.hidden_layers]\n",
    "    activation_per_layer = [layer.activation.__name__ for layer in model.hidden_layers]\n",
    "    data = data._append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"evaluate_max_reward\": np.max(evaluate_rewards),\n",
    "            \"evaluate_rewards_mean\": np.mean(evaluate_rewards),\n",
    "            \"evaluate_rewards_std\": np.std(evaluate_rewards),\n",
    "            \"hidden_layers\": len(model.hidden_layers),\n",
    "            \"units_per_layer\": units_per_layer,\n",
    "            \"activation_per_layer\": activation_per_layer,\n",
    "            \"output_layer_activation\": model.output_layer.activation.__name__,\n",
    "            **hyperparams,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "data.to_csv(\"mountain/results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
